\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{Abbreviations}

\begin{tabular}{ll}
\textbf{VarQBM}  & Variational Quantum Boltzmann Machine \\
\textbf{DNN}  & Dense Neural Network \\
\textbf{OLS}  & Ordinary Least Squares \\
\textbf{RSS}  & Residual Sum of Squares \\
\textbf{MSE}  & Mean Squared Error \\
\textbf{SGD}  & Stochastic Gradient Descent \\
\textbf{EMA}  & Exponential Moving Average \\
\textbf{NQS}  & Neural-network Quantum State \\
\textbf{VarITE}  & Variational imaginary time evolution \\
\textbf{MCC}  & Merchant Category Code\\
\end{tabular}


Checklist of things to do while writiting:
- Write transaction data instead of fraud data\\
- Go through the thesis and fix it so only equations that are referred to are labeled with a number\\
- Include complexity analysis of the circuits either in the appendix or theory, or discusson not sure\\
- The Franke function or Franke's function??\\
-Go through citations:
    --Be consistent
    --Remove months, only keep year
    --Only first page, remove pp xx-xx
    -- example (23, Taut)
    --remove bad articles
    --Phys. Rev is forkortet, be consisten all over the other citations\\
-Define the used ansatzes and Hamiltonians in the theory
- Add theory on the idea of using a neural network as H coefficients
- Add theory on bias and sample vector in varQBM in theory and give the section the following label: sec:bias\_dot\_product\\
-Add a list of activation functions?\\
- Plot the different activation functions used? A plot consisting of all 4 or 4 subfigures, maybe include the derivative also in the plots?
-Do I need to include all abbreviations or just the important ones?\\
- Fix figures to look nice, rbm from  \url{https://www.annualreviews.org/doi/pdf/10.1146/annurev-statistics-010814-020120} is quiet nice. Maybe make them myself? \url{https://www.mathcha.io/} is pretty nice.\\
- Go through the todo's in the code and in the latex document\\
-Add quantum information theory? afterwords in book
- Remove space under and over equations? Be consistent atleast\\
-Github: Write Readme and make public
- Comment code
- Remove results to the appendix, and make a table instead of the found parameters, als replot some of the plots using a log space.
- Remove citations using toward datascience and wikipedia and such
- An RBM, An NN, an nn- algorithm is the noun not NN when googling
-, or . after equations

Todays tasks:\\
- Expectation values and Hamiltonian measurement
- Fill write sections in chapter 4
- Read chapter 4
Monday:\\
- Go through chapter 5 and write the missing sections
- Read through chapter 5
- Write about qiskit
- Write about the results of classical data
- Write method about classical rbm, last touch of implementation?
Tuesday:\\
- Plot results of classical data
- Insert it and discuss everything with the classical data
Wednesday:\\
- Plot classic RBM
- Insert results and discuss them
- Do some missing coding and fix plots and such

Thursday:\\
- Go through the list above
- Write conclusion, introduction and abstract

Friday:
- Fix code, make public and add comments
- Write readme file



\end{document}