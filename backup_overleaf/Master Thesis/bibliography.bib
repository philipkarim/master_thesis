@book
{
    AM69,
    AUTHOR = {Atiyah, M. F. and Macdonald, I. G.},
     TITLE = {Introduction to commutative algebra},
 PUBLISHER = {Addison-Wesley Publishing Co., Reading, Mass.-London-Don
              Mills, Ont.},
      YEAR = {1969},
     PAGES = {ix+128},
   MRCLASS = {13.00},
  MRNUMBER = {0242802 (39 \#4129)},
MRREVIEWER = {J. A. Johnson},
}

@book{HastieTrevor2009EoSL,
series = {Springer series in statistics},
abstract = {Covers supervised learning (prediction) to unsupervised learning. This book contains topics including neural networks, support vector machines, classification trees and boosting.},
publisher = {Springer},
booktitle = {<h>Elements</h> of <h>Statistical</h> <h>Learning</h>},
isbn = {0387848576},
year = {2009},
title = {Elements of Statistical Learning: Data Mining, Inference, and Prediction},
language = {eng},
address = {New York},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
keywords = {Data mining ; Supervised learning (Machine learning) ; Mathematical statistics},
}

@misc{chain_rule,
   author = "Shane De Silva",
   title = "The Maths behind Back Propagation",
   year = "2020",
   url = "\url{ https://towardsdatascience.com/the-maths-behind-back-propagation-cf6714736abf}",
   note = "[Online; accessed 8-June-2021]"
 }
 
 @misc{cite:nnfig,
    author = "{Facundo Bre}",
    title = "Prediction of wind pressure coefficients on building surfaces using Artificial Neural Networks",
    year = "2017",
    howpublished = "\url{https://www.researchgate.net/figure/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o_fig1_321259051}",
    note = "[Online; accessed 4-April-2021]"
  }
  
  @misc{fig_RBM,
    author = {Artem Oppermann},
    title = "Deep Learning meets Physics: Restricted Boltzmann Machines Part I",
    year = "2018",
    howpublished = "\url{https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15}",
    note = "[Online; accessed 18-Mai-2021]"
  }
  
@misc{BM_book,
    author = {Hjorth-Jensen, M.},
    title = "Advanced Topics in Computational Physics: Computational Quantum Mechanics",
    year = "2021",
    howpublished = "\url{https://compphysics.github.io/ComputationalPhysics2/doc/LectureNotes/_build/html/intro.html}",
    note = "[Online; accessed 18-Mai-2021]"
  }
@ARTICLE{Hinton:2007,
AUTHOR = {Hinton, G. E.},
TITLE   = {{B}oltzmann machine},
YEAR    = {2007},
JOURNAL = {Scholarpedia},
VOLUME  = {2},
NUMBER  = {5},
PAGES   = {1668},
DOI     = {10.4249/scholarpedia.1668},
NOTE    = {revision \#91076}
}

 @misc{BMfig,
   author = "Wikimedia Commons",
   title = "File:Boltzmannexamplev1.png --- Wikimedia Commons{,} the free media repository",
   year = "2021",
   url = "\url{https://commons.wikimedia.org/w/index.php?title=File:Boltzmannexamplev1.png&oldid=560934009}",
   note = "[Online; accessed 31-July-2021]"
 }
 
@article{VQB:litteraturelist,
   title={Variational quantum Boltzmann machines},
   volume={3},
   ISSN={2524-4914},
   url={http://dx.doi.org/10.1007/s42484-020-00033-7},
   DOI={10.1007/s42484-020-00033-7},
   number={1},
   journal={Quantum Machine Intelligence},
   publisher={Springer Science and Business Media LLC},
   author={Zoufal, Christa and Lucchi, Aurélien and Woerner, Stefan},
   year={2021},
   month={Feb}
}

@misc{andrychowicz2016learning,
      title={Learning to learn by gradient descent by gradient descent}, 
      author={Marcin Andrychowicz and Misha Denil and Sergio Gomez and Matthew W. Hoffman and David Pfau and Tom Schaul and Brendan Shillingford and Nando de Freitas},
      year={2016},
      eprint={1606.04474},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@misc{ruder2017overview,
  doi = {10.48550/ARXIV.1609.04747},
  
  url = {https://arxiv.org/abs/1609.04747},
  
  author = {Ruder, Sebastian},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {An overview of gradient descent optimization algorithms},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@book{griffiths_schroeter_2018,
        place={Cambridge}, 
        edition={3}, 
        title={Introduction to Quantum Mechanics}, DOI={10.1017/9781316995433}, 
        publisher={Cambridge University Press}, 
        author={Griffiths, David J. and Schroeter, Darrell F.}, year={2018}}
        
        
@article{solving_manybody_with_ann,
  title = {Solving the quantum many-bodyproblem with artificialneural networks},
  author = {Carleo, G. and Troyer, M.},
  journal = {Science},
  volume = {355},
  issue = {6325},
  pages = {602-606},
  numpages = {5},
  year = {2017},
  month = {February},
  publisher = {Science},
  doi = {10.1126/science.aag2302},
  url = {https://science.sciencemag.org/content/355/6325/602/tab-pdf}
}

@article{PhysRevA.48.3561,
  title = {Two electrons in an external oscillator potential: Particular analytic solutions of a Coulomb correlation problem},
  author = {Taut, M.},
  journal = {Phys. Rev. A},
  volume = {48},
  issue = {5},
  pages = {3561--3566},
  numpages = {0},
  year = {1993},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.48.3561},
  url = {https://link.aps.org/doi/10.1103/PhysRevA.48.3561}
}

@book{10.5555/1972505,
author = {Nielsen, Michael A. and Chuang, Isaac L.},
title = {Quantum Computation and Quantum Information: 10th Anniversary Edition},
year = {2011},
isbn = {1107002176},
publisher = {Cambridge University Press},
address = {USA},
edition = {10th},
abstract = {One of the most cited books in physics of all time, Quantum Computation and Quantum Information remains the best textbook in this exciting field of science. This 10th anniversary edition includes an introduction from the authors setting the work in context. This comprehensive textbook describes such remarkable effects as fast quantum algorithms, quantum teleportation, quantum cryptography and quantum error-correction. Quantum mechanics and computer science are introduced before moving on to describe what a quantum computer is, how it can be used to solve problems faster than 'classical' computers and its real-world implementation. It concludes with an in-depth treatment of quantum information. Containing a wealth of figures and exercises, this well-known textbook is ideal for courses on the subject, and will interest beginning graduate students and researchers in physics, computer science, mathematics, and electrical engineering.}
}

@misc{blochsphere_fig,
    author = "{Wikipedia contributors}",
    title = "Bloch sphere --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2021",
    howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Bloch_sphere&oldid=1008849646}",
    note = "[Online; accessed 29-March-2021]"
  }
  
    @misc{cite_circuit_explained,
   author = "Dominick Marciano",
   title = "Quantum Computing for Everyone - Part III: Quantum Circuits and OpenQASM{,} Code Project",
   year = "2018",
   url = "\url{https://www.codeproject.com/Articles/1182208/Quantum-Computing-for-Everyone-Part-III-Quantum-Ci}",
   note = "[Online; accessed 30-March-2021]"
 }
 
@misc{Qiskit_book2,
       author = {MD SAJID ANIS and H{\'e}ctor Abraham and AduOffei and others},
       title = {Qiskit: An Open-source Framework for Quantum Computing},
       year = {2021},
       doi = {10.5281/zenodo.2573505}
}

@misc{Qiskit_book,
       author = {MD SAJID ANIS and Abby-Mitchell and H{\'e}ctor Abraham and AduOffei and Rochisha Agarwal and Gabriele Agliardi and Merav Aharoni and Ismail Yunus Akhalwaya and Gadi Aleksandrowicz and Thomas Alexander and Matthew Amy and Sashwat Anagolum and Eli Arbel and Abraham Asfaw and Anish Athalye and Artur Avkhadiev and Carlos Azaustre and PRATHAMESH BHOLE and Abhik Banerjee and Santanu Banerjee and Will Bang and Aman Bansal and Panagiotis Barkoutsos and Ashish Barnawal and George Barron and George S. Barron and Luciano Bello and Yael Ben-Haim and M. Chandler Bennett and Daniel Bevenius and Dhruv Bhatnagar and Arjun Bhobe and Paolo Bianchini and Lev S. Bishop and Carsten Blank and Sorin Bolos and Soham Bopardikar and Samuel Bosch and Sebastian Brandhofer and Brandon and Sergey Bravyi and Nick Bronn and Bryce-Fuller and David Bucher and Artemiy Burov and Fran Cabrera and Padraic Calpin and Lauren Capelluto and Jorge Carballo and Gin{\'e}s Carrascal and Adam Carriker and Ivan Carvalho and Adrian Chen and Chun-Fu Chen and Edward Chen and Jielun (Chris) Chen and Richard Chen and Franck Chevallier and Kartik Chinda and Rathish Cholarajan and Jerry M. Chow and Spencer Churchill and CisterMoke and Christian Claus and Christian Clauss and Caleb Clothier and Romilly Cocking and Ryan Cocuzzo and Jordan Connor and Filipe Correa and Zachary Crockett and Abigail J. Cross and Andrew W. Cross and Simon Cross and Juan Cruz-Benito and Chris Culver and Antonio D. C{\'o}rcoles-Gonzales and Navaneeth D and Sean Dague and Tareq El Dandachi and Animesh N Dangwal and Jonathan Daniel and Marcus Daniels and Matthieu Dartiailh and Abd{\'o}n Rodr{\'\i}guez Davila and Faisal Debouni and Anton Dekusar and Amol Deshmukh and Mohit Deshpande and Delton Ding and Jun Doi and Eli M. Dow and Eric Drechsler and Eugene Dumitrescu and Karel Dumon and Ivan Duran and Kareem EL-Safty and Eric Eastman and Grant Eberle and Amir Ebrahimi and Pieter Eendebak and Daniel Egger and ElePT and Emilio and Alberto Espiricueta and Mark Everitt and Davide Facoetti and Farida and Paco Mart{\'\i}n Fern{\'a}ndez and Samuele Ferracin and Davide Ferrari and Axel Hern{\'a}ndez Ferrera and Romain Fouilland and Albert Frisch and Andreas Fuhrer and Bryce Fuller and MELVIN GEORGE and Julien Gacon and Borja Godoy Gago and Claudio Gambella and Jay M. Gambetta and Adhisha Gammanpila and Luis Garcia and Tanya Garg and Shelly Garion and James R. Garrison and Tim Gates and Leron Gil and Austin Gilliam and Aditya Giridharan and Juan Gomez-Mosquera and Gonzalo and Salvador de la Puente Gonz{\'a}lez and Jesse Gorzinski and Ian Gould and Donny Greenberg and Dmitry Grinko and Wen Guan and Dani Guijo and John A. Gunnels and Harshit Gupta and Naman Gupta and Jakob M. G{\"u}nther and Mikael Haglund and Isabel Haide and Ikko Hamamura and Omar Costa Hamido and Frank Harkins and Kevin Hartman and Areeq Hasan and Vojtech Havlicek and Joe Hellmers and {\L}ukasz Herok and Stefan Hillmich and Hiroshi Horii and Connor Howington and Shaohan Hu and Wei Hu and Junye Huang and Rolf Huisman and Haruki Imai and Takashi Imamichi and Kazuaki Ishizaki and Ishwor and Raban Iten and Toshinari Itoko and Alexander Ivrii and Ali Javadi and Ali Javadi-Abhari and Wahaj Javed and Qian Jianhua and Madhav Jivrajani and Kiran Johns and Scott Johnstun and Jonathan-Shoemaker and JosDenmark and JoshDumo and John Judge and Tal Kachmann and Akshay Kale and Naoki Kanazawa and Jessica Kane and Kang-Bae and Annanay Kapila and Anton Karazeev and Paul Kassebaum and Josh Kelso and Scott Kelso and Vismai Khanderao and Spencer King and Yuri Kobayashi and Kovi11Day and Arseny Kovyrshin and Rajiv Krishnakumar and Vivek Krishnan and Kevin Krsulich and Prasad Kumkar and Gawel Kus and Ryan LaRose and Enrique Lacal and Rapha{\"e}l Lambert and Haggai Landa and John Lapeyre and Joe Latone and Scott Lawrence and Christina Lee and Gushu Li and Jake Lishman and Dennis Liu and Peng Liu and Lolcroc and Abhishek K M and Liam Madden and Yunho Maeng and Saurav Maheshkar and Kahan Majmudar and Aleksei Malyshev and Mohamed El Mandouh and Joshua Manela and Manjula and Jakub Marecek and Manoel Marques and Kunal Marwaha and Dmitri Maslov and Pawe{\l} Maszota and Dolph Mathews and Atsushi Matsuo and Farai Mazhandu and Doug McClure and Maureen McElaney and Cameron McGarry and David McKay and Dan McPherson and Srujan Meesala and Dekel Meirom and Corey Mendell and Thomas Metcalfe and Martin Mevissen and Andrew Meyer and Antonio Mezzacapo and Rohit Midha and Daniel Miller and Zlatko Minev and Abby Mitchell and Nikolaj Moll and Alejandro Montanez and Gabriel Monteiro and Michael Duane Mooring and Renier Morales and Niall Moran and David Morcuende and Seif Mostafa and Mario Motta and Romain Moyard and Prakash Murali and Jan M{\"u}ggenburg and Tristan NEMOZ and David Nadlinger and Ken Nakanishi and Giacomo Nannicini and Paul Nation and Edwin Navarro and Yehuda Naveh and Scott Wyman Neagle and Patrick Neuweiler and Aziz Ngoueya and Johan Nicander and Nick-Singstock and Pradeep Niroula and Hassi Norlen and NuoWenLei and Lee James O'Riordan and Oluwatobi Ogunbayo and Pauline Ollitrault and Tamiya Onodera and Raul Otaolea and Steven Oud and Dan Padilha and Hanhee Paik and Soham Pal and Yuchen Pang and Ashish Panigrahi and Vincent R. Pascuzzi and Simone Perriello and Eric Peterson and Anna Phan and Kuba Pilch and Francesco Piro and Marco Pistoia and Christophe Piveteau and Julia Plewa and Pierre Pocreau and Alejandro Pozas-Kerstjens and Rafa{\l} Pracht and Milos Prokop and Viktor Prutyanov and Sumit Puri and Daniel Puzzuoli and Jes{\'u}s P{\'e}rez and Quant02 and Quintiii and Rafey Iqbal Rahman and Arun Raja and Roshan Rajeev and Isha Rajput and Nipun Ramagiri and Anirudh Rao and Rudy Raymond and Oliver Reardon-Smith and Rafael Mart{\'\i}n-Cuevas Redondo and Max Reuter and Julia Rice and Matt Riedemann and Rietesh and Drew Risinger and Marcello La Rocca and Diego M. Rodr{\'\i}guez and RohithKarur and Ben Rosand and Max Rossmannek and Mingi Ryu and Tharrmashastha SAPV and Nahum Rosa Cruz Sa and Arijit Saha and Abdullah Ash- Saki and Sankalp Sanand and Martin Sandberg and Hirmay Sandesara and Ritvik Sapra and Hayk Sargsyan and Aniruddha Sarkar and Ninad Sathaye and Bruno Schmitt and Chris Schnabel and Zachary Schoenfeld and Travis L. Scholten and Eddie Schoute and Mark Schulterbrandt and Joachim Schwarm and James Seaward and Sergi and Ismael Faro Sertage and Kanav Setia and Freya Shah and Nathan Shammah and Rohan Sharma and Yunong Shi and Jonathan Shoemaker and Adenilton Silva and Andrea Simonetto and Deeksha Singh and Divyanshu Singh and Parmeet Singh and Phattharaporn Singkanipa and Yukio Siraichi and Siri and Jes{\'u}s Sistos and Iskandar Sitdikov and Seyon Sivarajah and Magnus Berg Sletfjerding and John A. Smolin and Mathias Soeken and Igor Olegovich Sokolov and Igor Sokolov and Vicente P. Soloviev and SooluThomas and Starfish and Dominik Steenken and Matt Stypulkoski and Adrien Suau and Shaojun Sun and Kevin J. Sung and Makoto Suwama and Oskar S{\l}owik and Hitomi Takahashi and Tanvesh Takawale and Ivano Tavernelli and Charles Taylor and Pete Taylour and Soolu Thomas and Kevin Tian and Mathieu Tillet and Maddy Tod and Miroslav Tomasik and Caroline Tornow and Enrique de la Torre and Juan Luis S{\'a}nchez Toural and Kenso Trabing and Matthew Treinish and Dimitar Trenev and TrishaPe and Felix Truger and Georgios Tsilimigkounakis and Davindra Tulsi and Wes Turner and Yotam Vaknin and Carmen Recio Valcarce and Francois Varchon and Adish Vartak and Almudena Carrera Vazquez and Prajjwal Vijaywargiya and Victor Villar and Bhargav Vishnu and Desiree Vogt-Lee and Christophe Vuillot and James Weaver and Johannes Weidenfeller and Rafal Wieczorek and Jonathan A. Wildstrom and Jessica Wilson and Erick Winston and WinterSoldier and Jack J. Woehr and Stefan Woerner and Ryan Woo and Christopher J. Wood and Ryan Wood and Steve Wood and James Wootton and Matt Wright and Lucy Xing and Jintao YU and Bo Yang and Unchun Yang and Jimmy Yao and Daniyar Yeralin and Ryota Yonekura and David Yonge-Mallo and Ryuhei Yoshida and Richard Young and Jessie Yu and Lebin Yu and Christopher Zachow and Laura Zdanski and Helena Zhang and Iulia Zidaru and Christa Zoufal and aeddins-ibm and alexzhang13 and b63 and bartek-bartlomiej and bcamorrison and brandhsn and charmerDark and deeplokhande and dekel.meirom and dime10 and dlasecki and ehchen and fanizzamarco and fs1132429 and gadial and galeinston and georgezhou20 and georgios-ts and gruu and hhorii and hykavitha and itoko and jeppevinkel and jessica-angel7 and jezerjojo14 and jliu45 and jscott2 and klinvill and krutik2966 and ma5x and michelle4654 and msuwama and nico-lgrs and ntgiwsvp and ordmoj and sagar pahwa and pritamsinha2304 and ryancocuzzo and saswati-qiskit and septembrr and sethmerkel and sg495 and shaashwat and sternparky and strickroman and tigerjack and tsura-crisaldo and vadebayo49 and welien and willhbang and wmurphy-collabstar and yang.luh and Mantas {\v{C}}epulkovskis},
       title = {Qiskit: An Open-source Framework for Quantum Computing},
       year = {2021},
       doi = {10.5281/zenodo.2573505}
}




@article{Benedetti_2019,
	doi = {10.1088/2058-9565/ab4eb5},
	url = {https://doi.org/10.1088/2058-9565/ab4eb5},
	year = 2019,
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {4},
	number = {4},
	pages = {043001},
	author = {Marcello Benedetti and Erika Lloyd and Stefan Sack and Mattia Fiorentini},
	title = {Parameterized quantum circuits as machine learning models},
	journal = {Quantum Science and Technology},
	abstract = {Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.}
}

@book{10.5555/3309066,
author = {Schuld, Maria and Petruccione, Francesco},
title = {Supervised Learning with Quantum Computers},
year = {2018},
isbn = {3319964232},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {Quantum machine learning investigates how quantum computers can be used for data-driven
prediction and decision making. The books summarises and conceptualises ideas of this
relatively young discipline for an audience of computer scientists and physicists
from a graduate level upwards. It aims at providing a starting point for those new
to the field, showcasing a toy example of a quantum machine learning algorithm and
providing a detailed introduction of the two parent disciplines. For more advanced
readers, the book discusses topics such as data encoding into quantum states, quantum
algorithms and routines for inference and optimisation, as well as the construction
and analysis of genuine ``quantum learning models''. A special focus lies on supervised
learning, and applications for near-term quantum devices.}
}

@book{hemmer2005kvantemekanikk,
  title={Kvantemekanikk: P.C. Hemmer},
  author={Hemmer, P.C.},
  isbn={9788251920285},
  url={https://books.google.no/books?id=DWb-tgAACAAJ},
  year={2005},
  publisher={Tapir akademisk forlag}
}

@book{rojasRa:nnsystematic, author = {Rojas, Ra\'{u}l}, title = {Neural Networks: A Systematic Introduction}, year = {1996}, isbn = {3540605053}, publisher = {Springer-Verlag}, address = {Berlin, Heidelberg} }

@book{lecturenotes:cresser,
  title={Quantum Physics Notes},
  author={Cresser, J.D.},
  url={https://www.e-booksdirectory.com/details.php?ebook=6153},
  year={2009},
  publisher={Macquarie University 2009}
}

@misc{hanada2018markov,
      title={Markov Chain Monte Carlo for Dummies}, 
      author={Masanori Hanada},
      year={2018},
      eprint={1808.08490},
      archivePrefix={arXiv},
      primaryClass={hep-th}
}

@misc{robert2016metropolishastings,
      title={The Metropolis-Hastings algorithm}, 
      author={Christian P. Robert},
      year={2016},
      eprint={1504.01896},
      archivePrefix={arXiv},
      primaryClass={stat.CO}
}

@article{ACKLEY1985147,
title = {A learning algorithm for boltzmann machines},
journal = {Cognitive Science},
volume = {9},
number = {1},
pages = {147-169},
year = {1985},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(85)80012-4},
url = {https://www.sciencedirect.com/science/article/pii/S0364021385800124},
author = {David H. Ackley and Geoffrey E. Hinton and Terrence J. Sejnowski},
abstract = {The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.}
}

@article{McArdle_2019,
   title={Variational ansatz-based quantum simulation of imaginary time evolution},
   volume={5},
   ISSN={2056-6387},
   url={http://dx.doi.org/10.1038/s41534-019-0187-2},
   DOI={10.1038/s41534-019-0187-2},
   number={1},
   journal={npj Quantum Information},
   publisher={Springer Science and Business Media LLC},
   author={McArdle, Sam and Jones, Tyson and Endo, Suguru and Li, Ying and Benjamin, Simon C. and Yuan, Xiao},
   year={2019},
   month={Sep}
}

@article{PhysRev.96.1124,
  title = {Properties of Bethe-Salpeter Wave Functions},
  author = {Wick, G. C.},
  journal = {Phys. Rev.},
  volume = {96},
  issue = {4},
  pages = {1124--1134},
  numpages = {0},
  year = {1954},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRev.96.1124},
  url = {https://link.aps.org/doi/10.1103/PhysRev.96.1124}
}


@article{doi:10.1080/00268976400100041,
author = { A.D.   McLachlan },
title = {A variational solution of the time-dependent Schrodinger equation},
journal = {Molecular Physics},
volume = {8},
number = {1},
pages = {39-44},
year  = {1964},
publisher = {Taylor & Francis},
doi = {10.1080/00268976400100041},

URL = { 
        https://doi.org/10.1080/00268976400100041
    
},
eprint = { 
        https://doi.org/10.1080/00268976400100041
    
}

}


@article{Yuan_2019,
   title={Theory of variational quantum simulation},
   volume={3},
   ISSN={2521-327X},
   url={http://dx.doi.org/10.22331/q-2019-10-07-191},
   DOI={10.22331/q-2019-10-07-191},
   journal={Quantum},
   publisher={Verein zur Forderung des Open Access Publizierens in den Quantenwissenschaften},
   author={Yuan, Xiao and Endo, Suguru and Zhao, Qi and Li, Ying and Benjamin, Simon C.},
   year={2019},
   month={Oct},
   pages={191}
}

@article{Somma_2002,
   title={Simulating physical phenomena by quantum networks},
   volume={65},
   ISSN={1094-1622},
   url={http://dx.doi.org/10.1103/PhysRevA.65.042323},
   DOI={10.1103/physreva.65.042323},
   number={4},
   journal={Physical Review A},
   publisher={American Physical Society (APS)},
   author={Somma, R. and Ortiz, G. and Gubernatis, J. E. and Knill, E. and Laflamme, R.},
   year={2002},
   month={Apr}
}

@article{Amin_2018,
   title={Quantum Boltzmann Machine},
   volume={8},
   ISSN={2160-3308},
   url={http://dx.doi.org/10.1103/PhysRevX.8.021050},
   DOI={10.1103/physrevx.8.021050},
   number={2},
   journal={Physical Review X},
   publisher={American Physical Society (APS)},
   author={Amin, Mohammad H. and Andriyash, Evgeny and Rolfe, Jason and Kulchytskyy, Bohdan and Melko, Roger},
   year={2018},
   month={May}
}

@inproceedings{GibbsElementaryPI,
  title={Elementary Principles in Statistical Mechanics: Developed with Especial Reference to the Rational Foundation of Thermodynamics},
  author={J. Gibbs}
}

@article{Temme_2011,
   title={Quantum Metropolis sampling},
   volume={471},
   ISSN={1476-4687},
   url={http://dx.doi.org/10.1038/nature09770},
   DOI={10.1038/nature09770},
   number={7336},
   journal={Nature},
   publisher={Springer Science and Business Media LLC},
   author={Temme, K. and Osborne, T. J. and Vollbrecht, K. G. and Poulin, D. and Verstraete, F.},
   year={2011},
   month={Mar},
   pages={87–90}
}

@article{Yung_2012,
   title={A quantum-quantum Metropolis algorithm},
   volume={109},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.1111758109},
   DOI={10.1073/pnas.1111758109},
   number={3},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Yung, M.-H. and Aspuru-Guzik, A.},
   year={2012},
   month={Jan},
   pages={754–759}
}

@article{Poulin_2009,
   title={Sampling from the Thermal Quantum Gibbs State and Evaluating Partition Functions with a Quantum Computer},
   volume={103},
   ISSN={1079-7114},
   url={http://dx.doi.org/10.1103/PhysRevLett.103.220502},
   DOI={10.1103/physrevlett.103.220502},
   number={22},
   journal={Physical Review Letters},
   publisher={American Physical Society (APS)},
   author={Poulin, David and Wocjan, Pawel},
   year={2009},
   month={Nov}
}

@article{Motta_2019,
   title={Determining eigenstates and thermal states on a quantum computer using quantum imaginary time evolution},
   volume={16},
   ISSN={1745-2481},
   url={http://dx.doi.org/10.1038/s41567-019-0704-4},
   DOI={10.1038/s41567-019-0704-4},
   number={2},
   journal={Nature Physics},
   publisher={Springer Science and Business Media LLC},
   author={Motta, Mario and Sun, Chong and Tan, Adrian T. K. and O’Rourke, Matthew J. and Ye, Erika and Minnich, Austin J. and Brandão, Fernando G. S. L. and Chan, Garnet Kin-Lic},
   year={2019},
   month={Nov},
   pages={205–210}
}

@misc{brandao2019finite,
      title={Finite correlation length implies efficient preparation of quantum thermal states}, 
      author={Fernando G. S. L. Brandao and Michael J. Kastoryano},
      year={2019},
      eprint={1609.07877},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{kastoryano2016quantum,
      title={Quantum Gibbs Samplers: the commuting case}, 
      author={Michael J. Kastoryano and Fernando G. S. L. Brandao},
      year={2016},
      eprint={1409.3435},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@misc{crooks2019gradients,
      title={Gradients of parameterized quantum gates using the parameter-shift rule and gate decomposition}, 
      author={Gavin E. Crooks},
      year={2019},
      eprint={1905.13311},
      archivePrefix={arXiv},
      primaryClass={quant-ph}
}

@article{Schmidhuber_2015,
	doi = {10.1016/j.neunet.2014.09.003},
  
	url = {https://doi.org/10.1016%2Fj.neunet.2014.09.003},
  
	year = 2015,
	month = {jan},
  
	publisher = {Elsevier {BV}
},
  
	volume = {61},
  
	pages = {85--117},
  
	author = {Jürgen Schmidhuber},
  
	title = {Deep learning in neural networks: An overview},
  
	journal = {Neural Networks}
}

@misc{activation_cunctions_citation,
  doi = {10.48550/ARXIV.1811.03378},
  
  url = {https://arxiv.org/abs/1811.03378},
  
  author = {Nwankpa, Chigozie and Ijomah, Winifred and Gachagan, Anthony and Marshall, Stephen},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Activation Functions: Comparison of trends in Practice and Research for Deep Learning},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{amsgrad_article,
  doi = {10.48550/ARXIV.1904.09237},
  
  url = {https://arxiv.org/abs/1904.09237},
  
  author = {Reddi, Sashank J. and Kale, Satyen and Kumar, Sanjiv},
  
  keywords = {Machine Learning (cs.LG), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {On the Convergence of Adam and Beyond},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{padhi2021tabular,
  title={Tabular transformers for modeling multivariate time series},
  author={Padhi, Inkit and Schiff, Yair and Melnyk, Igor and Rigotti, Mattia and Mroueh, Youssef and Dognin, Pierre and Ross, Jerret and Nair, Ravi and Altman, Erik},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3565--3569},
  year={2021},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/document/9414142}
}

@misc{atman,
  doi = {10.48550/ARXIV.1910.03033},
  
  url = {https://arxiv.org/abs/1910.03033},
  
  author = {Altman, Erik R.},
  
  keywords = {Databases (cs.DB), Machine Learning (cs.LG), Performance (cs.PF), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Synthesizing Credit Card Transactions},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{UCI_repo2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@misc{gd_conv_scale,
  doi = {10.48550/ARXIV.1502.03167},
  
  url = {https://arxiv.org/abs/1502.03167},
  
  author = {Ioffe, Sergey and Szegedy, Christian},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{Timothy_Masters,
author = {Masters, Timothy},
title = {Practical Neural Network Recipes in C++},
year = {1993},
isbn = {0124790402},
publisher = {Academic Press Professional, Inc.},
address = {USA}
}

@article{scikitlearn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{rbm_article,
author = {Salakhutdinov, Ruslan},
title = {Learning Deep Generative Models},
journal = {Annual Review of Statistics and Its Application},
volume = {2},
number = {1},
pages = {361-385},
year = {2015},
doi = {10.1146/annurev-statistics-010814-020120},

URL = { 
        https://doi.org/10.1146/annurev-statistics-010814-020120
    
},
eprint = { 
        https://doi.org/10.1146/annurev-statistics-010814-020120
    
}
,
    abstract = { Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many artificial intelligence–related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. In this article, we review several popular deep learning models, including deep belief networks and deep Boltzmann machines. We show that (a) these deep generative models, which contain many layers of latent variables and millions of parameters, can be learned efficiently, and (b) the learned high-level feature representations can be successfully applied in many application domains, including visual object recognition, information retrieval, classification, and regression tasks. }
}

@article{article_rbm2,
author = {Fischer, Asja and Igel, Christian},
year = {2014},
month = {01},
pages = {25-39},
title = {Training restricted Boltzmann machines: An introduction},
volume = {47},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2013.05.025}
}

@book{mcmc_book,
  added-at = {2014-03-16T11:12:07.000+0100},
  author = {Gilks, W.R. and Richardson, S. and Spiegelhalter, D.},
  biburl = {https://www.bibsonomy.org/bibtex/2193890cd11f59aab40ec3b7e54660383/peter.ralph},
  interhash = {043efb21ab1baccde979a4c67aec6e4f},
  intrahash = {193890cd11f59aab40ec3b7e54660383},
  isbn = {9780412055515},
  keywords = {MCMC reference},
  lccn = {98033429},
  publisher = {Taylor \& Francis},
  series = {Chapman \& Hall/CRC Interdisciplinary Statistics},
  timestamp = {2014-03-16T11:12:07.000+0100},
  title = {Markov Chain Monte Carlo in Practice},
  url = {http://books.google.com/books?id=TRXrMWY\_i2IC},
  year = 1995
}

@misc{cite:kaggletitanic,
   author = "Kaggle contributors",
   title = "Titanic - Machine Learning from Disaster",
   url = "\url{https://www.kaggle.com/c/titanic/overview}",
   note = "[Online; accessed 1-April-2021]"
 }
 
 
@book{gentle_intro_qc,
author = {Rieffel, Eleanor and Polak, Wolfgang},
title = {Quantum Computing: A Gentle Introduction},
year = {2011},
isbn = {9780262015066},
publisher = {The MIT Press},
edition = {1st},
abstract = {The combination of two of the twentieth centurys most influential and revolutionary scientific theories, information theory and quantum mechanics, gave rise to a radically new view of computing and information. Quantum information processing explores the implications of using quantum mechanics instead of classical mechanics to model information and its processing. Quantum computing is not about changing the physical substrate on which computation is done from classical to quantum but about changing the notion of computation itself, at the most basic level. The fundamental unit of computation is no longer the bit but the quantum bit or qubit. This comprehensive introduction to the field offers a thorough exposition of quantum computing and the underlying concepts of quantum physics, explaining all the relevant mathematics and offering numerous examples. With its careful development of concepts and thorough explanations, the book makes quantum computing accessible to students and professionals in mathematics, computer science, and engineering. A reader with no prior knowledge of quantum physics (but with sufficient knowledge of linear algebra) will be able to gain a fluent understanding by working through the book. The text covers the basic building blocks of quantum information processing, quantum bits and quantum gates, showing their relationship to the key quantum concepts of quantum measurement, quantum state transformation, and entanglement between quantum subsystems; it treats quantum algorithms, discussing notions of complexity and describing a number of simple algorithms as well as the most significant algorithms to date; and it explores entanglement and robust quantum computation, investigating such topics as quantifying entanglement, decoherence, quantum error correction, and fault tolerance.}
}

@unknown{boopa,
author = {Fernández, Francisco},
year = {2019},
month = {03},
pages = {},
title = {The Born-Oppenheimer approximation},
doi = {10.13140/RG.2.2.21650.91840}
}

@article{hydrogen_model_figure,
author = {S. B. Doma and M. Abu-Shady and F. N. El-Gammal and A. A. Amer},
title = {Ground states of the hydrogen molecule and its molecular ion in the presence of a magnetic field using the variational Monte Carlo method},
journal = {Molecular Physics},
volume = {114},
number = {11},
pages = {1787-1793},
year  = {2016},
publisher = {Taylor & Francis},
doi = {10.1080/00268976.2016.1154198},

URL = { 
        https://doi.org/10.1080/00268976.2016.1154198
    
},
eprint = { 
        https://doi.org/10.1080/00268976.2016.1154198
    
}

}

@article{H2_experimental,
author = {Moskowitz, Jules W. and Kalos, M. H.},
title = {A new look at correlations in atomic and molecular systems. I. Application of fermion monte carlo variational method},
journal = {International Journal of Quantum Chemistry},
volume = {20},
number = {5},
pages = {1107-1119},
doi = {https://doi.org/10.1002/qua.560200508},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/qua.560200508},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/qua.560200508},
abstract = {Abstract We are engaged in research directed toward the development of compact and accurate correlation functions for many-electron systems. Our computational tool is the variational method in which the many-electron integrals are calculated by Monte Carlo using the fermion Metropolis sampling algorithm. That is, a many-fermion system is simulated by sampling the square of a correlated antisymmetric wave function. The principal advantage of the method is that interelectronic distance rij may be included directly in the wave function without adding significant computational complexity. In addition, other quantities of physical and theoretical interest such as electron correlation functions and representations of Coulomb and Fermi “holes” are very easily obtained. Preliminary results are reported for He, H2, and Li2.},
year = {1981}
}

@INPROCEEDINGS{cyclical_lr,  author={Smith, Leslie N.},  booktitle={2017 IEEE Winter Conference on Applications of Computer Vision (WACV)},   title={Cyclical Learning Rates for Training Neural Networks},   year={2017},  volume={},  number={},  pages={464-472},  doi={10.1109/WACV.2017.58}}